

import os
import sys
import argparse
import torch
from tqdm import tqdm

ROOT_DIR = "/private/od"
NEW_DIR = os.path.join(ROOT_DIR, "new")
if NEW_DIR not in sys.path:
    sys.path.insert(0, NEW_DIR)

from CADF_OD import ODFlowDataset, QwenFeatureExtractor  # noqa: E402


def main():
    parser = argparse.ArgumentParser(description="Precompute token features for m18_NY (Stacking Forest-GAN) using Qwen2-7B for NYC taxi grid OD data")
    parser.add_argument("--io_flow_path", type=str, default="/private/od/data_NYTaxi/io_flow_daily.npy")
    parser.add_argument("--graph_path", type=str, default="/private/od/data_NYTaxi/graph.npy")
    parser.add_argument("--od_matrix_path", type=str, default="/private/od/data_NYTaxi/od_matrix_daily.npy")
    parser.add_argument("--output_path", type=str, default="/private/od/data_NYTaxi/token_features/precomputed_token_features_m18.pt")
    parser.add_argument("--token_dim", type=int, default=768)
    parser.add_argument("--seed", type=int, default=42)
    parser.add_argument("--device", type=str, default=("cuda:0" if torch.cuda.is_available() else "cpu"))
    args = parser.parse_args()

    # åˆ›å»ºè¾“å‡ºç›®å½•
    out_dir = os.path.dirname(args.output_path)
    os.makedirs(out_dir, exist_ok=True)

    print(f"é¢„è®¡ç®— m18_NY çš„ Token ç‰¹å¾ï¼ˆçº½çº¦å‡ºç§Ÿè½¦ç½‘æ ¼ODæ•°æ®ï¼‰")
    print(f"è¾“å‡ºè·¯å¾„: {args.output_path}")
    print(f"è®¾å¤‡: {args.device}")
    print(f"Tokenç»´åº¦: {args.token_dim}")
    print("-" * 60)

    # æ•°æ®é›†ï¼ˆä¸ m18_NY ä¸€è‡´ï¼Œé»˜è®¤ 20% æµ‹è¯•ã€10% éªŒè¯ï¼Œä»…ç”¨äºè®¿é—® io_flow ä¸åŒºåŸŸå¯¹ï¼‰
    dataset = ODFlowDataset(
        io_flow_path=args.io_flow_path,
        graph_path=args.graph_path,
        od_matrix_path=args.od_matrix_path,
        test_ratio=0.2,
        val_ratio=0.1,
        seed=args.seed,
    )

    # ç‰¹å¾æå–å™¨ï¼ˆä½¿ç”¨ m18_NY çš„ QwenFeatureExtractorï¼‰
    print("æ­£åœ¨åŠ è½½ Qwen2 ç‰¹å¾æå–å™¨...")
    extractor = QwenFeatureExtractor(feature_dim=args.token_dim, device=args.device)
    print("ç‰¹å¾æå–å™¨åŠ è½½å®Œæˆ")
    print("-" * 60)

    token_features = {}
    total_pairs = len(dataset.od_pairs)

    print(f"å¼€å§‹å¤„ç† {total_pairs} ä¸ªç«™ç‚¹å¯¹...")
    print(f"æ•°æ®é›†èŠ‚ç‚¹æ•°: {dataset.num_nodes}, æ—¶é—´æ­¥æ•°: {dataset.time_steps}")
    print(f"é¢„æœŸèŠ‚ç‚¹æ•°: 52 (å¦‚æœæ•°æ®å·²æ›´æ–°ä¸º52èŠ‚ç‚¹ç‰ˆæœ¬)")
    
    for idx, (site_i, site_j) in enumerate(tqdm(dataset.od_pairs, desc="é¢„è®¡ç®— Token ç‰¹å¾ (m18_NY)")):
        # è·å–IOæµæ•°æ®
        # æ³¨æ„ï¼šio_flow çš„å®é™…æ ¼å¼æ˜¯ (æ—¶é—´æ­¥, åŒºåŸŸæ•°, 2)
        # æ‰€ä»¥éœ€è¦æ­£ç¡®è®¿é—®æ•°æ®
        io_i = dataset.io_flow[:, site_i, :]  # (æ—¶é—´æ­¥, 2)
        io_j = dataset.io_flow[:, site_j, :]  # (æ—¶é—´æ­¥, 2)
        
        # å¦‚æœæ—¶é—´æ­¥æ•°è¶…è¿‡28ï¼Œåªå–å‰28å¤©ï¼ˆä¸æ¨¡å‹è®­ç»ƒä¸€è‡´ï¼‰
        time_steps = io_i.shape[0]
        if time_steps > 28:
            io_i = io_i[:28]
            io_j = io_j[:28]

        io_i_t = torch.FloatTensor(io_i).to(args.device)
        io_j_t = torch.FloatTensor(io_j).to(args.device)

        try:
            with torch.no_grad():
                # è°ƒç”¨ç‰¹å¾æå–å™¨ï¼Œä½¿ç”¨çº½çº¦å‡ºç§Ÿè½¦æ•°æ®çš„æç¤ºè¯æ¨¡æ¿
                feat, _ = extractor(
                    site_i, 
                    site_j, 
                    io_i_t, 
                    io_j_t, 
                    dataset.station_data if hasattr(dataset, 'station_data') else None,
                    prompt_type="nyc"  # ä½¿ç”¨çº½çº¦å‡ºç§Ÿè½¦æ•°æ®çš„æç¤ºè¯
                )

            token_features[f"{site_i}_{site_j}"] = feat.cpu()

            # å®šæœŸä¿å­˜ä¸­é—´ç»“æœ
            if (idx + 1) % 100 == 0:
                print(f"\nå·²å¤„ç† {idx + 1}/{total_pairs} ä¸ªåŒºåŸŸå¯¹ï¼Œä¿å­˜ä¸­é—´ç»“æœ...")
                torch.save(token_features, args.output_path)
                # æ¸…ç†GPUç¼“å­˜
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
        
        except Exception as e:
            import traceback
            error_msg = str(e)
            # åªæ‰“å°å‰å‡ ä¸ªé”™è¯¯çš„è¯¦ç»†å †æ ˆï¼Œé¿å…è¾“å‡ºè¿‡å¤š
            if idx < 3:
                print(f"\nè­¦å‘Š: å¤„ç†åŒºåŸŸå¯¹ ({site_i}, {site_j}) æ—¶å‡ºé”™: {error_msg}")
                print(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
                traceback.print_exc()
            elif "Numpy is not available" in error_msg:
                # å¯¹äºnumpyé”™è¯¯ï¼Œå°è¯•ä½¿ç”¨numpyæ•°ç»„è€Œä¸æ˜¯tensor
                try:
                    import numpy as np
                    io_i_np = io_i_t.cpu().numpy() if hasattr(io_i_t, 'cpu') else io_i_t
                    io_j_np = io_j_t.cpu().numpy() if hasattr(io_j_t, 'cpu') else io_j_t
                    # é‡æ–°å°è¯•ï¼Œä½†è¿™æ¬¡ä½¿ç”¨numpyæ•°ç»„
                    # å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œè·³è¿‡è¿™ä¸ªæ ·æœ¬
                    continue
                except:
                    continue
            else:
                # å…¶ä»–é”™è¯¯ï¼Œåªæ‰“å°ç®€è¦ä¿¡æ¯
                if (idx + 1) % 100 == 0:
                    print(f"\nè­¦å‘Š: å¤„ç†åŒºåŸŸå¯¹ ({site_i}, {site_j}) æ—¶å‡ºé”™: {error_msg[:100]}")
            continue

    # ä¿å­˜æœ€ç»ˆç»“æœ
    torch.save(token_features, args.output_path)
    print(f"\n{'='*60}")
    print(f"âœ… å®Œæˆï¼ä¿å­˜äº† {len(token_features)} ä¸ªåŒºåŸŸå¯¹çš„ token ç‰¹å¾")
    print(f"ğŸ“ ä¿å­˜è·¯å¾„: {args.output_path}")
    print(f"{'='*60}")


if __name__ == "__main__":
    main() 